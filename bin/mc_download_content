#!/usr/bin/env python3

"""
Downloads the content of one or more movie urls.
"""

import argparse
import asyncio
import os

from pathlib import Path
from metacritic import common
from metacritic import scraper
from metacritic.scraper import DEFAULT_SENTINEL
from metacritic.scraper import USER_AGENT


async def main(dir, sentinel_filename, refresh, concurrency):
    suffixes = scraper.get_suffixes_to_download(
        dir, sentinel_filename, refresh=refresh)
    result = await scraper.download_and_write_urls(
        dir, suffixes, concurrency)
    if any(result):
        Path(os.path.join(dir, sentinel)).touch()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="""\
    Download metacritic review HTML content for specified url suffixes.
    """)
    parser.add_argument(
        "--sentinel",
        help="""\
        A file in the suffix_dir that is touched to indicate one or more \
        url contents were downloaded. Default: __CONTENT_UPDATED.
        """)
    parser.add_argument(
        "--concurrency",
        help="""\
        How many urls to download concurrently?
        """,
        default=4,
        type=int)
    parser.add_argument(
        "--refresh",
        help="""\
        If set, download url contents even if they already exist.
        """,
        default=False,
        action="store_true")
    parser.add_argument(
        "suffix_dir",
        help="""\
        Directory that contains metacritic url suffixes. Each filename in \
        the directory is a url suffix.
        """)
    args = parser.parse_args()
    sentinel = args.sentinel if args.sentinel else DEFAULT_SENTINEL
    asyncio.run(main(args.suffix_dir, sentinel, args.refresh, args.concurrency))
