#!/usr/bin/env python3

"""
Downloads the content of one or more movie urls.
"""

import argparse
import asyncio
import os

from pathlib import Path
from metacritic import common
from metacritic import scraper
from metacritic.scraper import DEFAULT_SENTINEL
from metacritic.scraper import USER_AGENT


async def main(dir, sentinel_filename, refresh):
    suffix_url_map = scraper.get_urls_to_download(
        dir, sentinel_filename, refresh=refresh)
    common.debug("urls to download: " + str(suffix_url_map))
    result = await scraper.download_urls(
        suffix_url_map.values(), {'User-Agent': USER_AGENT})
    written = 0
    for suffix, url in suffix_url_map.items():
        if url not in result:
            continue # TODO: log error!?
        with open(os.path.join(dir, suffix), 'w') as f:
            f.write(result[url])
            written += 1
    if written:
        Path(os.path.join(dir, sentinel)).touch()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="""\
    Download metacritic review HTML content for specified url suffixes.
    """)
    parser.add_argument(
        "--sentinel",
        help="""\
        A file in the suffix_dir that is touched to indicate one or more \
        url contents were downloaded. Default: __CONTENT_UPDATED.
        """)
    parser.add_argument(
        "--refresh",
        help="""\
        If set, download url contents even if they already exist.
        """,
        default=False,
        action="store_true")
    parser.add_argument(
        "suffix_dir",
        help="""\
        Directory that contains metacritic url suffixes. Each filename in \
        the directory is a url suffix.
        """)
    args = parser.parse_args()
    sentinel = args.sentinel if args.sentinel else DEFAULT_SENTINEL
    asyncio.run(main(args.suffix_dir, sentinel, args.refresh))
